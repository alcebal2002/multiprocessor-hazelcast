// Controller properties
// Default values:
//   loadHistoricalData true
//   writeResultsToFile true
//   monitorDelay 10
//   queueproducer.numberOfTasks 1000
//   queueproducer.sleepTime 5
//   queueproducer.sendStopProcessingSignal true

controller.loadHistoricalData = true
controller.historicalDataPath = C:\\Users\\aocs\\Trabajo\\git-workspace\\multiprocessor-hazelcast\\src\\main\\resources\\historical_data\\
controller.historicalDataFileExtension = .csv
controller.historicalDataSeparator = ,
controller.writeResultsToFile = false
controller.monitorDelay = 10
# numberOfTasks only used when simulating ExecutionTasks
controller.queueproducer.numberOfTasks = 10000
controller.queueproducer.sleepTime = 0
controller.queueproducer.sendStopProcessingSignal = true
controller.worker.logFilePattern = yyyy-MM-dd HHmmss
controller.worker.logFileExtension = .csv
controller.execution.tasksGrouping = 1500
controller.execution.increasePercentage = 0.1
controller.execution.decreasePercentage = 0.05
controller.execution.maxLevels = 16

// Worker Pool properties
workerpool.coreSize = 4
workerpool.maxSize = 4
workerpool.queueCapacity = 1
workerpool.timeoutSecs = 50
# processTime only used when simulating ExecutionTasks
workerpool.processTime = 10
workerpool.retrySleepTime = 50
workerpool.retryMaxAttempts = 10
workerpool.initialSleep = 5
workerpool.monitorSleep = 10
workerpool.refreshAfter = 100

// Spark properties
spark.templatePath = /templates/
spark.publicPath = /public/
spark.templateFileName = result.ftl

// Hazelcast properties
hz.taskQueueName = taskQueue
hz.resultsQueueName = resultsQueue
hz.historicalDataMapName = historicalMap
hz.monitorMapName = monitorMap
hz.statusMapName = statusMap
hz.stopProcessingSignal = STOP_PROCESSING_SIGNAL